import os
import xml.etree.ElementTree as ET
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder

# === ì‚¬ìš©ì ê²½ë¡œ ì„¤ì • ===
ANNOTATIONS_DIR = "F:/gjlee/ëŒ€í•™ì›/ì˜ìƒì²˜ë¦¬ ì‹¤ì œ/annotations"
IMAGES_DIR = "F:/gjlee/ëŒ€í•™ì›/ì˜ìƒì²˜ë¦¬ ì‹¤ì œ/images"
MODEL_SAVE_PATH = "F:/gjlee/ëŒ€í•™ì›/ì˜ìƒì²˜ë¦¬ ì‹¤ì œ/2024254020.h5"
LABELS_TXT_PATH = "F:/gjlee/ëŒ€í•™ì›/ì˜ìƒì²˜ë¦¬ ì‹¤ì œ/dog_species_name.txt"

# === ì–´ë…¸í…Œì´ì…˜ íŒŒì‹± ===
def parse_annotation(filepath):
    try:
        tree = ET.parse(filepath)
        root = tree.getroot()

        filename = root.find("filename").text
        if not filename.endswith(".jpg"):
            filename += ".jpg"

        label = root.find("object").find("name").text
        return filename, label
    except:
        return None, None

# === ì´ë¯¸ì§€ ì „ì²´ ê²½ë¡œ ë§¤í•‘ ===
image_map = {}
for dirpath, _, files in os.walk(IMAGES_DIR):
    for file in files:
        if file.endswith(".jpg"):
            image_map[file] = os.path.join(dirpath, file)

# === ì–´ë…¸í…Œì´ì…˜ ë§¤ì¹­ ===
pairs = []
for dirpath, _, files in os.walk(ANNOTATIONS_DIR):
    for file in files:
        xml_path = os.path.join(dirpath, file)
        fname, label = parse_annotation(xml_path)
        if fname in image_map:
            pairs.append((image_map[fname], label))
        else:
            print(f"[â— ëˆ„ë½ ì´ë¯¸ì§€] {fname} â†’ SKIP")

if not pairs:
    raise RuntimeError("â— í•™ìŠµ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

# === ë¼ë²¨ ì¸ì½”ë”© ===
filepaths, labels = zip(*pairs)
label_encoder = LabelEncoder()
encoded_labels = label_encoder.fit_transform(labels)

# === TF Dataset êµ¬ì„± ===
def load_image(filepath, label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [224, 224])
    return image / 255.0, label

dataset = tf.data.Dataset.from_tensor_slices((list(filepaths), list(encoded_labels)))
dataset = dataset.map(load_image).shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)

# === ëª¨ë¸ êµ¬ì„± (Functional API) ===
inputs = tf.keras.Input(shape=(224, 224, 3))
base_model = tf.keras.applications.MobileNetV2(input_tensor=inputs,
                                                include_top=False,
                                                weights='imagenet')
base_model.trainable = False

x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)
x = tf.keras.layers.Dense(128, activation='relu')(x)
outputs = tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# === í•™ìŠµ ===
print(f"ğŸš€ í•™ìŠµ ì‹œì‘ (ì´ ì´ë¯¸ì§€: {len(pairs)})")
model.fit(dataset, epochs=5)

# === ì €ì¥ ===
model.save(MODEL_SAVE_PATH)
print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {MODEL_SAVE_PATH}")


# === ê²¬ì¢… ì´ë¦„ ì €ì¥ ì½”ë“œ ì—¬ê¸° ì¶”ê°€ ===
with open(LABELS_TXT_PATH, "w", encoding="utf-8") as f:
    for breed in label_encoder.classes_:
        f.write(f"{breed}\n")
print(f"ğŸ“„ ê²¬ì¢… ì´ë¦„ ì €ì¥ ì™„ë£Œ: {LABELS_TXT_PATH}")
